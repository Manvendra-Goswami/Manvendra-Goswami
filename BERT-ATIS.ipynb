{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNMsAwU2nIuQK4tSULgnlJs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manvendra-Goswami/Manvendra-Goswami/blob/main/BERT-ATIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b3I3JLOI6uzg",
        "outputId": "304496cf-5d13-4dd4-9d97-3042c8669b3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "# verify GPU availability\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp\n",
        "\n",
        "# BERT imports\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# specify GPU device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "9B85gienAKXD",
        "outputId": "654bd448-82d6-4260-ad66-98a99a37da67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.63.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.37)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.10.0.2)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.5.2)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.37 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.24.37)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.37->boto3->pytorch-pretrained-bert) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.37->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.37->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.10.8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla K80'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "DATA_DIR=\".\"\n",
        "\n",
        "# load Pickle file \n",
        "def load_ds(fname=os.path.join(DATA_DIR,'/atis.train.pkl'), verbose=True):\n",
        "    with open(fname, 'rb') as stream:\n",
        "        ds,dicts = pickle.load(stream)\n",
        "    if verbose:\n",
        "      print('Done  loading: ', fname)\n",
        "      print('      samples: {:4d}'.format(len(ds['query'])))\n",
        "      print('   vocab_size: {:4d}'.format(len(dicts['token_ids'])))\n",
        "      print('   slot count: {:4d}'.format(len(dicts['slot_ids'])))\n",
        "      print(' intent count: {:4d}'.format(len(dicts['intent_ids'])))\n",
        "    return ds,dicts\n",
        "  \n",
        "# convert Pickle file to arrays\n",
        "def load_atis(filename, add_start_end_token=False, verbose=True):\n",
        "    train_ds, dicts = load_ds(os.path.join(DATA_DIR,filename), verbose)\n",
        "    t2i, s2i, in2i = map(dicts.get, ['token_ids', 'slot_ids','intent_ids'])\n",
        "    i2t, i2s, i2in = map(lambda d: {d[k]:k for k in d.keys()}, [t2i,s2i,in2i])\n",
        "    query, slots, intent =  map(train_ds.get, ['query', 'slot_labels', 'intent_labels'])\n",
        "\n",
        "    if add_start_end_token:\n",
        "        i2s[178] = 'BOS'\n",
        "        i2s[179] = 'EOS'\n",
        "        s2i['BOS'] = 178\n",
        "        s2i['EOS'] = 179\n",
        "\n",
        "    input_tensor = []\n",
        "    target_tensor = []\n",
        "    query_data = []\n",
        "    intent_data = []\n",
        "    slot_data = []\n",
        "    to_show = np.random.randint(0, len(query)-1, 5)\n",
        "    for i in range(len(query)):\n",
        "        input_tensor.append(query[i])\n",
        "        slot_text = []\n",
        "        slot_vector = []\n",
        "        for j in range(len(query[i])):\n",
        "            slot_text.append(i2s[slots[i][j]])\n",
        "            slot_vector.append(slots[i][j])\n",
        "        if add_start_end_token:\n",
        "            slot_text[0] = 'BOS'\n",
        "            slot_vector[0] = 178\n",
        "            slot_text[-1] = 'EOS'\n",
        "            slot_vector[-1]= 179\n",
        "        target_tensor.append(slot_vector)\n",
        "        q = ' '.join(map(i2t.get, query[i]))\n",
        "        query_data.append(q.replace('BOS', '').replace('EOS',''))\n",
        "        intent_data.append(i2in[intent[i][0]])\n",
        "        slot = ' '.join(slot_text)\n",
        "        slot_data.append(slot[1:-1])\n",
        "        if i in to_show and verbose:\n",
        "          print('Query text:', q)\n",
        "          print('Query vector: ', query[i])\n",
        "          print('Intent label: ', i2in[intent[i][0]])\n",
        "          print('Slot text: ', slot)\n",
        "          print('Slot vector: ', slot_vector)\n",
        "          print('*'*74)\n",
        "    query_data = np.array(query_data)\n",
        "    intent_data = np.array(intent_data)\n",
        "    slot_data = np.array(slot_data)\n",
        "    intent_data_label = np.array(intent).flatten()\n",
        "    return t2i, s2i, in2i, i2t, i2s, i2in, input_tensor, target_tensor, \n",
        "           query_data, intent_data, intent_data_label, slot_data\n",
        "\n",
        "# load ATIS training dataset\n",
        "t2i_train, s2i_train, in2i_train, i2t_train, i2s_train, i2in_train, \\\n",
        "input_tensor_train, target_tensor_train, \\\n",
        "query_data_train, intent_data_train, intent_data_label_train, slot_data_train = load_atis('atis.train.pkl')\n",
        "\n",
        "# load ATIS testing dataset\n",
        "t2i_test, s2i_test, in2i_test, i2t_test, i2s_test, i2in_test, \\\n",
        "input_tensor_test, target_tensor_test, \\\n",
        "query_data_test, intent_data_test, intent_data_label_test, slot_data_test = load_atis('atis.test.pkl')"
      ],
      "metadata": {
        "id": "PBkKrLaLA4wD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}